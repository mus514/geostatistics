{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing audio recordings using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a coding environment to use Tensorflow\n",
    "\n",
    "https://www.pnas.org/doi/10.1073/pnas.2004702117\n",
    "\n",
    "https://onlinelibrary.wiley.com/doi/10.1111/oik.08525\n",
    "\n",
    "https://github.com/tensorflow/models/tree/master/research/audioset/vggish\n",
    "\n",
    "https://zenodo.org/records/3907296\n",
    "\n",
    "\n",
    "To create the environment for this workflow follow the following steps:\n",
    "1) Install Anaconda (https://www.anaconda.com/download/)\n",
    "2) Create and activate environment, using powershell\n",
    "```\n",
    "conda create --name soundScape python=3.10\n",
    "conda activate soundScape\n",
    "```\n",
    "\n",
    "3) Install base libraries\n",
    "```\n",
    "conda install -c conda-forge mamba\n",
    "mamba install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0 cudatoolkit-dev ipykernel nbformat numpy scipy\n",
    "python -m pip install \"tensorflow<2.11\" tf-slim resampy soundfile\n",
    "```\n",
    "\n",
    "4) Check tensorflow install\n",
    "```\n",
    "python -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n",
    "```\n",
    "\n",
    "5) Copy vggish\n",
    "```\n",
    "# \"G:\\Shared drives\\Projets\\Actif\\2023_ECCC4_Biodiv\\3-Analyses\\2-Analyses\\vggish\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing your install of VGGish\n",
      "\n",
      "Resampling via resampy works!\n",
      "Log Mel Spectrogram example:  [[-4.48313252 -4.27083405 -4.17064267 ... -4.60069383 -4.60098887\n",
      "  -4.60116305]\n",
      " [-4.48313252 -4.27083405 -4.17064267 ... -4.60069383 -4.60098887\n",
      "  -4.60116305]\n",
      " [-4.48313252 -4.27083405 -4.17064267 ... -4.60069383 -4.60098887\n",
      "  -4.60116305]\n",
      " ...\n",
      " [-4.48313252 -4.27083405 -4.17064267 ... -4.60069383 -4.60098887\n",
      "  -4.60116305]\n",
      " [-4.48313252 -4.27083405 -4.17064267 ... -4.60069383 -4.60098887\n",
      "  -4.60116305]\n",
      " [-4.48313252 -4.27083405 -4.17064267 ... -4.60069383 -4.60098887\n",
      "  -4.60116305]]\n",
      "VGGish embedding:  [-2.73169428e-01 -1.80366933e-01  5.19998372e-02 -1.43594891e-01\n",
      " -1.04789361e-01 -4.96687800e-01 -1.75353721e-01  4.23048645e-01\n",
      " -8.22081447e-01 -2.16846049e-01 -1.17590576e-01 -6.70083344e-01\n",
      "  1.43157810e-01 -1.44236773e-01  8.80868733e-03 -8.71441662e-02\n",
      " -1.84470892e-01  5.96522272e-01 -3.43975008e-01 -5.78861833e-02\n",
      " -1.64907858e-01  4.22914624e-02 -2.55291790e-01 -2.36321270e-01\n",
      "  1.80356130e-01  3.02820683e-01  1.08540192e-01 -4.48482633e-01\n",
      "  1.22710302e-01 -2.99926937e-01 -5.55860460e-01  5.06039143e-01\n",
      "  2.05351055e-01  8.87692750e-01  9.03800607e-01 -2.10582450e-01\n",
      " -3.28518897e-02  1.38663575e-01 -2.27391079e-01  1.14793777e-01\n",
      "  5.95306337e-01 -4.76943791e-01  2.28199050e-01  1.54414535e-01\n",
      "  1.64694801e-01  7.19388008e-01  1.24109662e+00  5.61996400e-01\n",
      "  2.73574620e-01  3.10608447e-02  2.10997671e-01 -6.09492183e-01\n",
      " -3.15333217e-01  1.76362485e-01 -8.96776915e-02 -4.26834255e-01\n",
      "  3.13148320e-01 -1.56582490e-01  3.31643879e-01  1.29489392e-01\n",
      "  1.66065276e-01  3.00878435e-02 -1.54514462e-01 -4.29359138e-01\n",
      " -2.68666267e-01 -1.58089802e-01  4.00440007e-01 -2.56066382e-01\n",
      " -2.66573746e-02  8.00402462e-03  2.98482925e-01  3.48766893e-01\n",
      " -1.07185021e-01  8.88209492e-02  1.26826614e-01 -3.34808320e-01\n",
      " -2.55290002e-01  5.08087993e-01  3.97615820e-01  1.78718865e-01\n",
      " -8.04384872e-02  4.83676791e-02 -2.01197684e-01 -2.97960073e-01\n",
      "  3.66963506e-01  4.56172466e-01  5.37917733e-01 -2.00847909e-02\n",
      " -6.24290258e-02  4.15678859e-01 -1.88742265e-01 -5.36941409e-01\n",
      " -1.78414285e-01  3.81270260e-01  3.96782637e-01  3.21993828e-01\n",
      " -4.27313633e-02 -1.41022682e-01 -4.53762531e-01 -1.06991529e-01\n",
      " -2.21830621e-01  3.51129234e-01 -2.58455038e-01  3.30994815e-01\n",
      " -7.29109049e-01 -2.55441546e-01  3.56324345e-01 -3.16009641e-01\n",
      "  3.12720418e-01  1.23365514e-01 -1.83199868e-02 -3.99623543e-01\n",
      " -5.13566077e-01 -2.74240255e-01 -2.68676102e-01  2.24103794e-01\n",
      "  1.09398931e-01  1.30903214e-01 -1.26120508e-01 -1.92663491e-01\n",
      "  2.27361917e-04  2.04131544e-01 -1.03136361e-01  2.92757750e-02\n",
      " -3.38435084e-01 -2.25745410e-01 -2.46826991e-01 -1.20758891e-01]\n",
      "embedding mean/stddev 0.0006448515 0.34303734\n",
      "Postprocessed VGGish embedding:  [160  53 124 132 154 120 119 105 155 173 129  69 149  93  59   0  52  97\n",
      " 157 144 153 194 251 108  48 174 131 190 195  79  59  60 169  93 167 247\n",
      "  28  75 255  56 134 169 234 138 232 100  19  80 162 255   0 255 101   0\n",
      " 222 252  79 210  64  88 248   0   0 255 246  62  81 255   0 159  22 168\n",
      "  70 255  99 135 204 192 255 150   0   0 255 255  67 235  55 255  69   0\n",
      "   0  17 241  44 255 224   0 255  40   0 255   0 211 252  62   0  28 218\n",
      " 112   0 255   0  81  67 153   0 255   0 129 229  53 255  55 101   0 255\n",
      "   0 255]\n",
      "postproc embedding mean/stddev 126.359375 89.33239669688358\n",
      "\n",
      "Looks Good To Me!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 09:12:53.154741: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-18 09:12:54.573515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5450 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "c:\\Users\\Jurie\\anaconda3\\envs\\soundScape\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "c:\\Users\\Jurie\\anaconda3\\envs\\soundScape\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\core.py:332: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n",
      "2024-04-18 09:12:54.898285: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2024-04-18 09:13:17.624593: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2024-04-18 09:13:20.196874: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "# Load package\n",
    "import os\n",
    "\n",
    "# Specity parameters\n",
    "script=\"\\\"P:/Projets/Actif/2023_ECCC4_Biodiv/3-Analyses/2-Analyses/vggish/vggish_smoke_test.py\\\"\"\n",
    "\n",
    "# Change directory\n",
    "os.chdir('P:\\\\Projets\\\\Actif\\\\2023_ECCC4_Biodiv\\\\3-Analyses\\\\2-Analyses\\\\vggish')\n",
    "\n",
    "# Run terminal command\n",
    "!python {script}\n",
    "\n",
    "# Change back directory\n",
    "os.chdir('C:\\\\Projects\\\\2023_ECCC4_Biodiv\\\\1.SoundEmbedding_VGGish')\n",
    "\n",
    "# Clean environment\n",
    "del script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/drive/1E3CaPAqCai9P9QhJ3WYPNCVmrJU4lAhF#scrollTo=O1YVQb-MBiUx\n",
    "\n",
    "https://github.com/tensorflow/models/tree/master/research/audioset/vggish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jurie\\anaconda3\\envs\\soundScape\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "c:\\Users\\Jurie\\anaconda3\\envs\\soundScape\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\core.py:332: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from P:\\\\Projets\\\\Actif\\\\2023_ECCC4_Biodiv\\\\3-Analyses\\\\2-Analyses\\\\vggish\\\\vggish_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Load packages\n",
    "from __future__ import print_function\n",
    "\n",
    "# Change directory\n",
    "import os\n",
    "os.chdir('P:\\\\Projets\\\\Actif\\\\2023_ECCC4_Biodiv\\\\3-Analyses\\\\2-Analyses\\\\vggish')\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "import vggish_input\n",
    "import vggish_params\n",
    "import vggish_postprocess\n",
    "import vggish_slim\n",
    "\n",
    "# Specify file locations\n",
    "waveFile=r\"P:/Projets/Actif/2023_ECCC4_Biodiv/3-Analyses/2-Analyses/vggish/Testing/test.wav\"\n",
    "pcaParms=r\"P:\\\\Projets\\\\Actif\\\\2023_ECCC4_Biodiv\\\\3-Analyses\\\\2-Analyses\\\\vggish\\\\vggish_pca_params.npz\"\n",
    "checkP=r\"P:\\\\Projets\\\\Actif\\\\2023_ECCC4_Biodiv\\\\3-Analyses\\\\2-Analyses\\\\vggish\\\\vggish_model.ckpt\"\n",
    "\n",
    "# Prepare wave file\n",
    "examples_batch = vggish_input.wavfile_to_examples(waveFile)\n",
    "\n",
    "# Prepare a postprocessor to munge the model embeddings.\n",
    "pproc = vggish_postprocess.Postprocessor(pcaParms)\n",
    "\n",
    "# Define the model in inference mode, load the checkpoint, \n",
    "# and locate input and output tensors.\n",
    "with tf.Graph().as_default(), tf.Session() as sess:    \n",
    "    vggish_slim.define_vggish_slim(training=False)\n",
    "    vggish_slim.load_vggish_slim_checkpoint(sess,checkP)\n",
    "    features_tensor = sess.graph.get_tensor_by_name(\n",
    "        vggish_params.INPUT_TENSOR_NAME)\n",
    "    embedding_tensor = sess.graph.get_tensor_by_name(\n",
    "        vggish_params.OUTPUT_TENSOR_NAME)\n",
    "\n",
    "    # Run inference and postprocessing.\n",
    "    [embedding_batch] = sess.run([embedding_tensor],\n",
    "                                 feed_dict={features_tensor: examples_batch})\n",
    "    postprocessed_batch = pproc.postprocess(embedding_batch)\n",
    "\n",
    "# Clean environment\n",
    "del print_function, waveFile, pcaParms, checkP, examples_batch, pproc, sess\n",
    "del features_tensor, embedding_tensor, embedding_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[137  87 114 104  80  15 235 110 208 125 164  86 191 134 186  97 185  70\n",
      "  91 207 160 129 218 108  83 180  58 136 255 137   0  21 178  80 170 146\n",
      " 127  75  41  71 107 126 117 115 124  23  50 160 153 116 110 255 166  60\n",
      " 205 185   9 122   0 141 140  57  79 114 106  49  60  96 173  37 126 143\n",
      " 232 148  63  62  19 221 255  57 157  55 165 255 217  15 229 165 181  90\n",
      " 221 189 159 180 113  98 158 130  39 186  86  95  13  34 255 179 197  62\n",
      "  35   0  94 173  86 109   4 126 133  61 117   0 150 188 170  92 235  68\n",
      "  35 138]\n"
     ]
    }
   ],
   "source": [
    "print(postprocessed_batch[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soundScape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
