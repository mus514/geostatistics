{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing audio recordings using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a coding environment to use Tensorflow\n",
    "\n",
    "https://www.pnas.org/doi/10.1073/pnas.2004702117\n",
    "\n",
    "https://onlinelibrary.wiley.com/doi/10.1111/oik.08525\n",
    "\n",
    "https://github.com/tensorflow/models/tree/master/research/audioset/vggish\n",
    "\n",
    "https://zenodo.org/records/3907296\n",
    "\n",
    "\n",
    "To create the environment for this workflow follow the following steps:\n",
    "1) Install Anaconda (https://www.anaconda.com/download/)\n",
    "2) Create and activate environment, using powershell\n",
    "```\n",
    "conda create --name soundScape python=3.10\n",
    "conda activate soundScape\n",
    "```\n",
    "\n",
    "3) Install base libraries\n",
    "```\n",
    "conda install -c conda-forge mamba\n",
    "mamba install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0 cudatoolkit-dev ipykernel nbformat numpy scipy\n",
    "python -m pip install \"tensorflow<2.11\" tf-slim resampy soundfile\n",
    "```\n",
    "\n",
    "4) Check tensorflow install\n",
    "```\n",
    "python -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n",
    "```\n",
    "\n",
    "5) Copy vggish\n",
    "```\n",
    "# \"G:\\Shared drives\\Projets\\Actif\\2023_ECCC4_Biodiv\\3-Analyses\\2-Analyses\\vggish\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/drive/1E3CaPAqCai9P9QhJ3WYPNCVmrJU4lAhF#scrollTo=O1YVQb-MBiUx\n",
    "\n",
    "https://github.com/tensorflow/models/tree/master/research/audioset/vggish\n",
    "\n",
    "https://github.com/tensorflow/models/blob/master/research/audioset/vggish/vggish_train_demo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: loss 0.696466\n",
      "Step 1: loss 0.694889\n",
      "Step 2: loss 0.693323\n",
      "Step 3: loss 0.691771\n",
      "Step 4: loss 0.690225\n",
      "Step 5: loss 0.68869\n",
      "Step 6: loss 0.687164\n",
      "Step 7: loss 0.685649\n",
      "Step 8: loss 0.684151\n",
      "Step 9: loss 0.682666\n",
      "Step 10: loss 0.681186\n",
      "Step 11: loss 0.679716\n",
      "Step 12: loss 0.678263\n",
      "Step 13: loss 0.676821\n",
      "Step 14: loss 0.675379\n",
      "Step 15: loss 0.67396\n",
      "Step 16: loss 0.672544\n",
      "Step 17: loss 0.671142\n",
      "Step 18: loss 0.669753\n",
      "Step 19: loss 0.668371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 15:45:33.109010: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-26 15:45:33.712496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5450 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "c:\\Users\\Jurie\\anaconda3\\envs\\soundScape\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "c:\\Users\\Jurie\\anaconda3\\envs\\soundScape\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\core.py:332: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n",
      "2024-06-26 15:45:34.599119: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "INFO:tensorflow:Restoring parameters from P:\\Projets\\Actif\\2023_ECCC4_Biodiv\\3-Analyses\\2-Analyses\\vggish\\vggish_model.ckpt\n",
      "I0626 15:45:35.852332 28156 saver.py:1410] Restoring parameters from P:\\Projets\\Actif\\2023_ECCC4_Biodiv\\3-Analyses\\2-Analyses\\vggish\\vggish_model.ckpt\n",
      "2024-06-26 15:46:02.117121: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2024-06-26 15:46:08.541547: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "# Specity parameters\n",
    "script=\"\\\"C:/Projects/2023_ECCC4_Biodiv/6.BirdTransfereLearning/vggish_train.py\\\"\"\n",
    "data_path=\"\\\"C:/Users/Jurie/Desktop/VGGish_transfer_learning_data\\\"\"\n",
    "model_saved_path=\"\\\"P:/Projets/Actif/2023_ECCC4_Biodiv/3-Analyses/2-Analyses/Fine_Tuned_Bird_Model\\\"\"\n",
    "\n",
    "# Run terminal command\n",
    "!python {script} --num_batches 20 --num_units 100 --train_vggish=False --_NUM_CLASSES 3 --data_path {data_path} --model_saved_path {model_saved_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[0.50816524 0.51649326 0.4742054 ]\n",
      " [0.48452118 0.5010323  0.45452964]\n",
      " [0.51822746 0.5058652  0.4632561 ]\n",
      " [0.46989432 0.41727766 0.4205827 ]\n",
      " [0.5032104  0.48684517 0.42770538]\n",
      " [0.5002762  0.5110371  0.46943647]\n",
      " [0.47058296 0.510253   0.4101257 ]\n",
      " [0.48229095 0.5119603  0.4632344 ]\n",
      " [0.5185407  0.503988   0.48020592]\n",
      " [0.48956704 0.51232976 0.44047752]\n",
      " [0.49554595 0.4754516  0.43008384]\n",
      " [0.5193809  0.5252369  0.46190527]\n",
      " [0.48738706 0.43887824 0.434222  ]\n",
      " [0.51930934 0.50040036 0.45064166]\n",
      " [0.4876032  0.46114442 0.38721654]\n",
      " [0.480481   0.5252765  0.47085956]\n",
      " [0.4925799  0.5192422  0.3936627 ]\n",
      " [0.48519555 0.45814112 0.45107076]\n",
      " [0.5088823  0.49923906 0.46741572]\n",
      " [0.478486   0.45230237 0.44223654]\n",
      " [0.5066587  0.47697797 0.48992696]\n",
      " [0.5123584  0.5313728  0.4608509 ]\n",
      " [0.49222705 0.49288934 0.43106696]\n",
      " [0.55344    0.4886327  0.49478355]\n",
      " [0.4947077  0.4790139  0.4565901 ]\n",
      " [0.49459967 0.50301826 0.45125178]\n",
      " [0.55489767 0.48204517 0.5004328 ]\n",
      " [0.49359468 0.49107835 0.45391643]\n",
      " [0.545728   0.47186828 0.5107534 ]\n",
      " [0.4858596  0.49296606 0.45504925]\n",
      " [0.47792432 0.43055633 0.432015  ]\n",
      " [0.48382422 0.48619506 0.44988734]\n",
      " [0.5207616  0.4876817  0.48189408]\n",
      " [0.4926632  0.5235181  0.5185629 ]\n",
      " [0.47727326 0.53541297 0.40233433]\n",
      " [0.493663   0.49689046 0.41101965]\n",
      " [0.47095093 0.48954087 0.4519841 ]\n",
      " [0.46090767 0.4644809  0.43708602]\n",
      " [0.4382212  0.4467807  0.4445791 ]\n",
      " [0.4869553  0.5092167  0.3836035 ]\n",
      " [0.5073347  0.5008342  0.45179492]\n",
      " [0.4818344  0.4847392  0.37632224]\n",
      " [0.49420488 0.53899944 0.4545648 ]\n",
      " [0.4813835  0.50420636 0.46692893]\n",
      " [0.49828747 0.5257587  0.44628003]\n",
      " [0.46399015 0.52629334 0.4810904 ]\n",
      " [0.50580114 0.53126645 0.4556102 ]\n",
      " [0.4969385  0.48840967 0.42282593]\n",
      " [0.48167086 0.49577898 0.3781126 ]\n",
      " [0.45044807 0.50145525 0.37182695]\n",
      " [0.4637423  0.5116776  0.4155869 ]\n",
      " [0.48254973 0.5594914  0.46434295]\n",
      " [0.47029728 0.46045345 0.3949737 ]\n",
      " [0.483869   0.53676945 0.475418  ]\n",
      " [0.4576796  0.4995187  0.45998335]\n",
      " [0.4767578  0.5169342  0.47627544]\n",
      " [0.46374643 0.50487894 0.44576684]\n",
      " [0.46943888 0.50905555 0.47552451]\n",
      " [0.44695535 0.46601745 0.4885388 ]\n",
      " [0.45575845 0.50966156 0.4475851 ]\n",
      " [0.41257915 0.46654522 0.43527412]\n",
      " [0.41835645 0.46677825 0.4388002 ]\n",
      " [0.42503184 0.45296445 0.44085258]\n",
      " [0.41552827 0.47406632 0.4664811 ]\n",
      " [0.40592024 0.4773374  0.47311836]\n",
      " [0.41239008 0.47150153 0.42869663]\n",
      " [0.40656245 0.47701526 0.45277673]\n",
      " [0.4429755  0.49014145 0.49179405]\n",
      " [0.41348198 0.4784066  0.48656443]\n",
      " [0.43180037 0.4866099  0.44870088]\n",
      " [0.46941328 0.47697148 0.49393332]\n",
      " [0.4289757  0.48559445 0.4487901 ]\n",
      " [0.43809673 0.48519948 0.45219085]\n",
      " [0.43863103 0.48519105 0.47324082]\n",
      " [0.42059013 0.48761827 0.43254402]\n",
      " [0.42223093 0.47493544 0.4393095 ]\n",
      " [0.43520844 0.49608532 0.4333394 ]\n",
      " [0.44385606 0.47180882 0.4681322 ]\n",
      " [0.46654013 0.48208153 0.45745778]\n",
      " [0.4320303  0.4847381  0.44388285]\n",
      " [0.42488253 0.4897609  0.4386737 ]\n",
      " [0.46187246 0.49731937 0.44510597]\n",
      " [0.4374483  0.4969806  0.44715407]\n",
      " [0.45485    0.4783428  0.4678533 ]\n",
      " [0.4549263  0.48771963 0.46921295]\n",
      " [0.4402262  0.5118506  0.44628426]\n",
      " [0.4399002  0.517594   0.44368693]\n",
      " [0.48158246 0.5108194  0.45687973]\n",
      " [0.4434059  0.49494833 0.4550287 ]\n",
      " [0.4469351  0.51725006 0.43474382]\n",
      " [0.43437427 0.51879954 0.41569883]\n",
      " [0.44662246 0.5074282  0.45478156]\n",
      " [0.45005888 0.49296188 0.43887645]\n",
      " [0.42943794 0.5183203  0.43856132]\n",
      " [0.4625996  0.48852247 0.47107565]\n",
      " [0.44505394 0.50537395 0.44908372]\n",
      " [0.41425306 0.43261942 0.36597583]\n",
      " [0.39610338 0.45657894 0.39674845]\n",
      " [0.44434336 0.49380535 0.40022707]\n",
      " [0.42859977 0.5364625  0.38424012]\n",
      " [0.40757024 0.49482617 0.37847656]\n",
      " [0.42962027 0.45354995 0.39854962]\n",
      " [0.43291232 0.4494125  0.37856618]\n",
      " [0.3965282  0.4542516  0.35485902]\n",
      " [0.38749313 0.42513314 0.3845806 ]\n",
      " [0.44080848 0.47434074 0.4484929 ]\n",
      " [0.43355483 0.49193987 0.37693274]\n",
      " [0.41719663 0.47509372 0.38611764]\n",
      " [0.4096509  0.45145255 0.40308473]\n",
      " [0.39130592 0.45695558 0.44578418]\n",
      " [0.38961613 0.41856724 0.39190492]\n",
      " [0.42315707 0.50273645 0.4058529 ]\n",
      " [0.4183047  0.40159845 0.42267165]\n",
      " [0.39638242 0.43982443 0.3627905 ]\n",
      " [0.46102065 0.5380337  0.47283536]\n",
      " [0.437447   0.5275886  0.44564483]\n",
      " [0.44187063 0.52037114 0.4716048 ]\n",
      " [0.45041567 0.5097289  0.4801171 ]\n",
      " [0.47540432 0.49181366 0.48426506]\n",
      " [0.4729214  0.55578464 0.45525903]\n",
      " [0.42471337 0.4853882  0.4618382 ]\n",
      " [0.36347497 0.4730873  0.4129743 ]\n",
      " [0.3974271  0.4725891  0.45050207]\n",
      " [0.48678532 0.43139604 0.5496772 ]\n",
      " [0.48026773 0.42762464 0.5088498 ]\n",
      " [0.46528623 0.46596995 0.5254774 ]\n",
      " [0.45776606 0.44748703 0.5198985 ]\n",
      " [0.46658963 0.4743265  0.49056393]\n",
      " [0.45202357 0.5017512  0.46596387]\n",
      " [0.47583234 0.43901077 0.51872367]\n",
      " [0.42697227 0.45621255 0.46097454]\n",
      " [0.49761155 0.39990908 0.52686983]\n",
      " [0.49969536 0.49259263 0.49199215]\n",
      " [0.4725101  0.5311466  0.46432152]\n",
      " [0.48561597 0.5458335  0.42631638]\n",
      " [0.40257606 0.5092633  0.3876745 ]\n",
      " [0.4376103  0.4990124  0.43434063]\n",
      " [0.4617293  0.52774924 0.45506352]\n",
      " [0.47201872 0.51417553 0.45018536]\n",
      " [0.5010327  0.54811144 0.4474242 ]\n",
      " [0.46427974 0.51715434 0.4648495 ]\n",
      " [0.4772165  0.5507622  0.44071424]\n",
      " [0.4817225  0.5756794  0.45260674]\n",
      " [0.42472744 0.4194513  0.41243583]\n",
      " [0.43911836 0.44239    0.40814665]\n",
      " [0.44828254 0.54076153 0.4209145 ]\n",
      " [0.47286978 0.5159529  0.43283695]\n",
      " [0.47554705 0.47393447 0.44130576]\n",
      " [0.4467012  0.51110226 0.45189354]\n",
      " [0.43396986 0.48098636 0.44933385]\n",
      " [0.5042681  0.5695216  0.40500438]\n",
      " [0.4716137  0.4865806  0.42440304]\n",
      " [0.4519583  0.474848   0.43622285]\n",
      " [0.5257615  0.60147023 0.38406384]\n",
      " [0.45800886 0.46731004 0.46045086]\n",
      " [0.4650684  0.46746823 0.4520905 ]\n",
      " [0.4744589  0.52472776 0.46358937]\n",
      " [0.503115   0.5231154  0.42663074]\n",
      " [0.481197   0.5443355  0.45412785]\n",
      " [0.53688145 0.554408   0.37400553]\n",
      " [0.5036323  0.5505663  0.4846315 ]\n",
      " [0.48825416 0.5412284  0.48729002]\n",
      " [0.5280749  0.6013548  0.44215354]\n",
      " [0.48822537 0.51873577 0.4349106 ]\n",
      " [0.46896964 0.5089731  0.4368176 ]\n",
      " [0.44986024 0.46039262 0.43682575]\n",
      " [0.4787455  0.4890769  0.45513335]\n",
      " [0.49013862 0.49745184 0.46911198]\n",
      " [0.47314557 0.54570365 0.43259642]\n",
      " [0.42680272 0.4858978  0.42944786]\n",
      " [0.44867057 0.5360382  0.42721236]\n",
      " [0.4849264  0.6174948  0.44273585]\n",
      " [0.46985474 0.55095553 0.47704992]\n",
      " [0.47236982 0.50779116 0.4880773 ]\n",
      " [0.46327913 0.537687   0.48565674]\n",
      " [0.4729951  0.53410083 0.4760558 ]\n",
      " [0.46209794 0.5330335  0.48315796]\n",
      " [0.4733675  0.48698473 0.42677182]\n",
      " [0.3865252  0.50147456 0.38059562]\n",
      " [0.42442837 0.49302962 0.3990379 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 15:47:50.310790: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-26 15:47:50.823463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5450 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "c:\\Users\\Jurie\\anaconda3\\envs\\soundScape\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "c:\\Users\\Jurie\\anaconda3\\envs\\soundScape\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\core.py:332: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n",
      "INFO:tensorflow:Restoring parameters from P:/Projets/Actif/2023_ECCC4_Biodiv/3-Analyses/2-Analyses/Fine_Tuned_Bird_Model\\final_model\n",
      "I0626 15:47:50.990137 14248 saver.py:1410] Restoring parameters from P:/Projets/Actif/2023_ECCC4_Biodiv/3-Analyses/2-Analyses/Fine_Tuned_Bird_Model\\final_model\n",
      "2024-06-26 15:47:51.001279: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2024-06-26 15:48:11.517534: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2024-06-26 15:48:15.549819: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "# Specity parameters\n",
    "script=\"\\\"C:/Projects/2023_ECCC4_Biodiv/6.BirdTransfereLearning/vggish_inference.py\\\"\"\n",
    "data_path=\"\\\"C:/Users/Jurie/Desktop/VGGish_transfer_learning_data\\\"\"\n",
    "model_saved_path=\"\\\"P:/Projets/Actif/2023_ECCC4_Biodiv/3-Analyses/2-Analyses/Fine_Tuned_Bird_Model\\\"\"\n",
    "\n",
    "# Run terminal command\n",
    "!python {script} --num_units 100 --_NUM_CLASSES 3 --data_path {data_path} --model_saved_path {model_saved_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('P:\\\\Projets\\\\Actif\\\\2023_ECCC4_Biodiv\\\\3-Analyses\\\\2-Analyses\\\\vggish')\n",
    "from __future__ import print_function\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tf_slim as slim\n",
    "import vggish_input\n",
    "import vggish_params\n",
    "import vggish_slim\n",
    "num_batches=30\n",
    "num_units=100\n",
    "train_vggish=False\n",
    "checkpoint='P:\\\\Projets\\\\Actif\\\\2023_ECCC4_Biodiv\\\\3-Analyses\\\\2-Analyses\\\\vggish\\\\vggish_model.ckpt'\n",
    "_NUM_CLASSES=3\n",
    "data_path='C:\\\\Users\\\\Jurie\\\\Desktop\\\\VGGish_transfer_learning_data'\n",
    "model_saved_path=\"C:\\\\Users\\\\Jurie\\\\Desktop\\\\New folder\\\\my_model_final\"\n",
    "saved_model=\"C:\\\\Users\\\\Jurie\\\\Desktop\\\\New folder\\\\my_model_final\"\n",
    "def _get_batches():\n",
    "  #Definition\n",
    "  #Returns a shuffled batch of examples with labels of all audio classes.\n",
    "  #\n",
    "  # Loop over files in folder and\n",
    "  # convert to vggish input format\n",
    "  files_list=[]\n",
    "  label_list=[]\n",
    "  folder_indices={}\n",
    "  folder_index=0\n",
    "  for root,_,files in os.walk(data_path):\n",
    "    if root not in folder_indices:\n",
    "      folder_indices[root]=folder_index\n",
    "      folder_index+=1\n",
    "    for file in files:\n",
    "      # Convert to vggish formate\n",
    "      examples=vggish_input.wavfile_to_examples(os.path.join(root,file))\n",
    "      # Create label\n",
    "      label=np.eye(_NUM_CLASSES,dtype=int)[folder_indices[root]-1].reshape(1, -1)\n",
    "      label=np.repeat(label,examples.shape[0],axis=0)\n",
    "      # Add to list\n",
    "      files_list.append(examples)\n",
    "      label_list.append(label)\n",
    "  # Concatenate results\n",
    "  concatenate_files=np.concatenate(files_list,axis=0)\n",
    "  concatenate_labels=np.concatenate(label_list,axis=0)\n",
    "  # Zip and shuffel\n",
    "  labeled_files=list(zip(concatenate_files,concatenate_labels))\n",
    "  shuffle(labeled_files)\n",
    "  # Separate and return the features and labels.\n",
    "  features=[example for (example,_) in labeled_files]\n",
    "  labels=[label for (_,label) in labeled_files]\n",
    "  # Return\n",
    "  return (features,labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model, add head, define loss/optimizer and train\n",
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    # Define VGGish.\n",
    "    embeddings=vggish_slim.define_vggish_slim(training=False)\n",
    "    # Define a shallow classification model\n",
    "    with tf.variable_scope('mymodel'):\n",
    "      # Add a fully connected layer\n",
    "      fc=slim.fully_connected(tf.nn.relu(embeddings),num_units)\n",
    "      # Add a classifier layer at the end (classification head), \n",
    "      # consisting of parallel logistic classifiers, one per class. \n",
    "      # This allows for multi-class tasks.\n",
    "      logits=slim.fully_connected(fc,_NUM_CLASSES,activation_fn=None,scope='logits')\n",
    "      tf.sigmoid(logits,name='prediction')\n",
    "      # Add training ops.\n",
    "      with tf.variable_scope('train'):\n",
    "        global_step=tf.train.create_global_step()\n",
    "        # Labels are assumed to be fed as a batch multi-hot vectors, with\n",
    "        # a 1 in the position of each positive class label, and 0 elsewhere.\n",
    "        labels_input=tf.placeholder(\n",
    "            tf.float32,shape=(None,_NUM_CLASSES),name='labels')\n",
    "        # Cross-entropy label loss.\n",
    "        xent=tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=labels_input,name='xent')\n",
    "        loss=tf.reduce_mean(xent,name='loss_op')\n",
    "        tf.summary.scalar('loss',loss)\n",
    "        # We use the same optimizer and hyperparameters as used to train VGGish.\n",
    "        optimizer=tf.train.AdamOptimizer(\n",
    "            learning_rate=vggish_params.LEARNING_RATE,\n",
    "            epsilon=vggish_params.ADAM_EPSILON)\n",
    "        train_op=optimizer.minimize(loss,global_step=global_step)\n",
    "    # Initialize all variables in the model, and then load the pre-trained\n",
    "    # VGGish checkpoint.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    vggish_slim.load_vggish_slim_checkpoint(sess,checkpoint)\n",
    "    # Define Saver to save the model\n",
    "    saver = tf.train.Saver()\n",
    "    # The training loop.\n",
    "    features_input=sess.graph.get_tensor_by_name(vggish_params.INPUT_TENSOR_NAME)\n",
    "    for _ in range(num_batches):\n",
    "      (features,labels)=_get_batches()\n",
    "      [num_steps,loss_value,_]=sess.run(\n",
    "          [global_step,loss,train_op],\n",
    "          feed_dict={features_input:features,labels_input:labels})\n",
    "      print('Step %d: loss %g' % (num_steps, loss_value))\n",
    "    # Save the final model\n",
    "    saver.save(sess,model_saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_batches():\n",
    "  #Definition\n",
    "  #Returns a shuffled batch of examples with labels of all audio classes.\n",
    "  #\n",
    "  # Loop over files in folder and\n",
    "  # convert to vggish input format\n",
    "  files_list=[]\n",
    "  folder_indices={}\n",
    "  folder_index=0\n",
    "  for root,_,files in os.walk(data_path):\n",
    "    if root not in folder_indices:\n",
    "      folder_indices[root]=folder_index\n",
    "      folder_index+=1\n",
    "    for file in files:\n",
    "      # Convert to vggish formate\n",
    "      examples=vggish_input.wavfile_to_examples(os.path.join(root,file))\n",
    "      # Create label\n",
    "      label=np.eye(_NUM_CLASSES,dtype=int)[folder_indices[root]-1].reshape(1, -1)\n",
    "      label=np.repeat(label,examples.shape[0],axis=0)\n",
    "      # Add to list\n",
    "      files_list.append(examples)\n",
    "  # Concatenate results\n",
    "  concatenate_files=np.concatenate(files_list,axis=0)\n",
    "  # Return\n",
    "  return (concatenate_files)\n",
    "\n",
    "\n",
    "# Load model, add head, define loss/optimizer and train\n",
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    # Define VGGish.\n",
    "    embeddings=vggish_slim.define_vggish_slim(training=False)\n",
    "    # Define a shallow classification model\n",
    "    with tf.variable_scope('mymodel'):\n",
    "      # Add a fully connected layer\n",
    "      fc=slim.fully_connected(tf.nn.relu(embeddings),num_units)\n",
    "      # Add a classifier layer at the end (classification head), \n",
    "      # consisting of parallel logistic classifiers, one per class. \n",
    "      # This allows for multi-class tasks.\n",
    "      logits=slim.fully_connected(fc,_NUM_CLASSES,activation_fn=None,scope='logits')\n",
    "      prediction=tf.sigmoid(logits, name='prediction')\n",
    "    # Restore the model from the checkpoint\n",
    "    saver=tf.train.Saver()\n",
    "    \n",
    "    saver.restore(sess,saved_model)\n",
    "    # Get new data for prediction\n",
    "    new_features=_get_batches()\n",
    "    # Get the tensor for the input features\n",
    "    features_input=sess.graph.get_tensor_by_name(vggish_params.INPUT_TENSOR_NAME)\n",
    "    # Run the prediction\n",
    "    predictions=sess.run(prediction,feed_dict={features_input:new_features})\n",
    "    # Print\n",
    "    print('Predictions:', predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soundScape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
